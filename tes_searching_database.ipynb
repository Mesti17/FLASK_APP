{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine, Column, String, Table, MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\FLASK_APP\\venv\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "f:\\FLASK_APP\\venv\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "f:\\FLASK_APP\\venv\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 60\u001b[0m\n\u001b[0;32m     52\u001b[0m         total_neg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     54\u001b[0m     all_data\u001b[39m.\u001b[39mappend({\n\u001b[0;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsername\u001b[39m\u001b[39m\"\u001b[39m: result\u001b[39m.\u001b[39musername,\n\u001b[0;32m     56\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mHasil\u001b[39m\u001b[39m\"\u001b[39m: result\u001b[39m.\u001b[39mcleaning,\n\u001b[0;32m     57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSentimen\u001b[39m\u001b[39m\"\u001b[39m: hasil_pred,        \n\u001b[0;32m     58\u001b[0m     })\n\u001b[1;32m---> 60\u001b[0m total_sentimen[\n\u001b[0;32m     61\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mTotal_Pos\u001b[39;49m\u001b[39m\"\u001b[39;49m: total_pos,\n\u001b[0;32m     62\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mTotal_Net\u001b[39;49m\u001b[39m\"\u001b[39;49m: total_net,\n\u001b[0;32m     63\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mTotal_Neg\u001b[39;49m\u001b[39m\"\u001b[39;49m: total_neg\n\u001b[0;32m     64\u001b[0m ]\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "all_data = []\n",
    "total_sentimen=dict()\n",
    "total_pos = 0\n",
    "total_net = 0\n",
    "total_neg = 0\n",
    "\n",
    "model_path = 'model/model_nb.pickle'\n",
    "modelNB = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "#Load Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "with open('model/vec.pickle', 'rb') as handle:\n",
    "    vectorizer = pickle.load(handle)\n",
    "\n",
    "engine = create_engine('mysql+pymysql://root:@localhost:3306/capres')\n",
    "conn1 = engine.connect()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# #Using pymysql\n",
    "\n",
    "table_name = 'hasil_preprocessing'  # Replace with the actual table name\n",
    "specific_word = 'Anies'  # Replace with the specific word you want to search\n",
    "\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "table = metadata.tables[table_name]\n",
    "\n",
    "# conn2 = pymysql.connect(host='localhost', port=int(3306), user='root', password='', db='capres')\n",
    "\n",
    "query = table.select().where(table.c.cleaning.like(f'%{specific_word}%')).limit(100)\n",
    "results = session.execute(query)\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    vec = vectorizer.transform([result.cleaning])\n",
    "    prediksi = modelNB.predict(vec)\n",
    "    \n",
    "    if prediksi == 1:\n",
    "            hasil_pred = 'POSITIF'\n",
    "            total_pos += 1\n",
    "    elif prediksi == 0:\n",
    "        hasil_pred = 'NETRAL'\n",
    "        total_net += 1\n",
    "    else:\n",
    "        hasil_pred = 'NEGATIF'\n",
    "        total_neg += 1\n",
    "    \n",
    "    all_data.append({\n",
    "        \"Username\": result.username,\n",
    "        \"Hasil\": result.cleaning,\n",
    "        \"Sentimen\": hasil_pred,        \n",
    "    })\n",
    "    \n",
    "total_sentimen[\"Total_Pos\"]= total_pos\n",
    "total_sentimen[\"Total_Net\"]= total_net\n",
    "total_sentimen[\"Total_Neg\"]= total_neg\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(all_data[\u001b[39m\"\u001b[39;49m\u001b[39mTotal_Pos\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "print(all_data[\"Total_Pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in results:\n",
    "    print(item.cleaning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
